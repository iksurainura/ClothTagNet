{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae6873f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import  transforms\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import yaml\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "362d4015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ━━━━━━━━━━━━ 6.2MB 1.3MB/s 4.9s 4.9s<0.4s7s8s\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolov8n.pt\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb2c92b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data_path, train_pct=0.8):\n",
    "    \"\"\"\n",
    "    Splits images and labels from a source directory into train/validation sets.\n",
    "    \n",
    "    Args:\n",
    "        data_path (str): Path to folder containing 'images' and 'labels' subfolders.\n",
    "        train_pct (float): Ratio of data to be used for training (0.01 to 0.99).\n",
    "    \"\"\"\n",
    "    # 1. Validation Logic\n",
    "    if not os.path.isdir(data_path):\n",
    "        print(f\"Error: {data_path} is not a valid directory.\")\n",
    "        return\n",
    "\n",
    "    if not (0.01 <= train_pct <= 0.99):\n",
    "        print(\"Error: train_pct must be between 0.01 and 0.99.\")\n",
    "        return\n",
    "\n",
    "    # 2. Setup Paths\n",
    "    input_image_path = os.path.join(data_path, 'images')\n",
    "    input_label_path = os.path.join(data_path, 'labels')\n",
    "    \n",
    "    cwd = os.getcwd()\n",
    "    dirs = {\n",
    "        'train_img': os.path.join(cwd, 'data/train/images'),\n",
    "        'train_txt': os.path.join(cwd, 'data/train/labels'),\n",
    "        'val_img':   os.path.join(cwd, 'data/validation/images'),\n",
    "        'val_txt':   os.path.join(cwd, 'data/validation/labels')\n",
    "    }\n",
    "\n",
    "    # 3. Create Folders\n",
    "    for path in dirs.values():\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    # 4. Gather Files\n",
    "    # Using list() to ensure we can remove items during the loop\n",
    "    img_file_list = list(Path(input_image_path).rglob('*'))\n",
    "    img_file_list = [f for f in img_file_list if f.is_file()] # Ensure no directories\n",
    "    \n",
    "    file_num = len(img_file_list)\n",
    "    train_num = int(file_num * train_pct)\n",
    "    \n",
    "    print(f\"Total images: {file_num}\")\n",
    "    print(f\"Splitting: {train_num} train | {file_num - train_num} validation\")\n",
    "\n",
    "    # 5. Process Split\n",
    "    # We shuffle once and then slice to avoid using random.choice + remove in a loop (faster)\n",
    "    random.shuffle(img_file_list)\n",
    "    \n",
    "    for i, img_path in enumerate(img_file_list):\n",
    "        # Determine destination based on current index\n",
    "        if i < train_num:\n",
    "            dest_img, dest_txt = dirs['train_img'], dirs['train_txt']\n",
    "        else:\n",
    "            dest_img, dest_txt = dirs['val_img'], dirs['val_txt']\n",
    "\n",
    "        # Setup filenames\n",
    "        img_fn = img_path.name\n",
    "        txt_fn = img_path.stem + '.txt'\n",
    "        txt_path = os.path.join(input_label_path, txt_fn)\n",
    "\n",
    "        # Copy Image\n",
    "        shutil.copy(img_path, os.path.join(dest_img, img_fn))\n",
    "        \n",
    "        # Copy Label (if exists)\n",
    "        if os.path.exists(txt_path):\n",
    "            shutil.copy(txt_path, os.path.join(dest_txt, txt_fn))\n",
    "\n",
    "    print(\"Dataset split complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d410577b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 77\n",
      "Splitting: 61 train | 16 validation\n",
      "Dataset split complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "split_dataset(\"Label_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "caa066d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created config file at data.yaml\n"
     ]
    }
   ],
   "source": [
    "def create_data_yaml(path_to_classes_txt, path_to_data_yaml):\n",
    "  if not os.path.exists(path_to_classes_txt):\n",
    "    print(f'classes.txt file not found! Please create a classes.txt labelmap and move it to {path_to_classes_txt}')\n",
    "    return\n",
    "  with open(path_to_classes_txt, 'r') as f:\n",
    "    classes = []\n",
    "    for line in f.readlines():\n",
    "      if len(line.strip()) == 0: continue\n",
    "      classes.append(line.strip())\n",
    "  number_of_classes = len(classes)\n",
    "\n",
    "  # Create data dictionary\n",
    "  data = {\n",
    "      'path': 'data',\n",
    "      'train': 'train/images',\n",
    "      'val': 'validation/images',\n",
    "      'nc': number_of_classes,\n",
    "      'names': classes\n",
    "  }\n",
    "\n",
    "  # Write data to YAML file\n",
    "  with open(path_to_data_yaml, 'w') as f:\n",
    "    yaml.dump(data, f, sort_keys=False)\n",
    "  print(f'Created config file at {path_to_data_yaml}')\n",
    "\n",
    "  return\n",
    "\n",
    "# Define path to classes.txt and run function\n",
    "path_to_classes_txt = 'Label_data/classes.txt'\n",
    "path_to_data_yaml = 'data.yaml'\n",
    "\n",
    "create_data_yaml(path_to_classes_txt, path_to_data_yaml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "448fc380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.240  Python-3.10.19 torch-2.9.1+cpu CPU (12th Gen Intel Core i5-12450H)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\runs\\detect\\train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.005, workers=2, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 268.4147.2 MB/s, size: 4494.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\labels... 61 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 61/61 35.0it/s 1.7s0.1s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\03155f59-PXL_20251008_154836331.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\05b9a7b7-PXL_20251008_151310254.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\08d07926-PXL_20251008_151943020.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\08d9dee7-PXL_20251008_152314572.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\093db7bc-PXL_20251008_151711964.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\09417fd4-PXL_20251008_155015408.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\0e44181d-PXL_20251008_154849571.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\131c191c-PXL_20251008_151933930.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\144dab81-PXL_20251008_155437708.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\1a79994a-PXL_20251008_155507864.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\1bfa23d0-PXL_20251008_151855620.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\2a6ff8dc-PXL_20251008_152329597.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\2ad169c4-PXL_20251008_152045588.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\2bb14a29-PXL_20251008_152245426.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\2e3e0204-PXL_20251008_153355444.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\3599c1e1-PXL_20251008_155456234.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\38a13379-PXL_20251008_153239686.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\40038049-PXL_20251008_153302746.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\4411b68d-PXL_20251008_151358463.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\46d45bb1-PXL_20251008_153221673.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\49dec0c9-PXL_20251008_151830438.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\4bf03b1e-PXL_20251008_155026714.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\4df8d424-PXL_20251008_154638591.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\4dfc5e67-PXL_20251008_155106952.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\55505c29-PXL_20251008_155303122.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\63539329-PXL_20251008_151330813.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\6c35c3d7-PXL_20251008_155339918.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\6c525499-PXL_20251008_155518192.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\735d59cd-PXL_20251008_151702032.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\75fd5ae3-PXL_20251008_155054311.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\7f88b7eb-PXL_20251008_152255499.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\8066dede-PXL_20251008_155041637.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\81a01a65-PXL_20251008_154822088.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\82f0418e-PXL_20251008_152304371.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\8944b6ee-PXL_20251008_155317718.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\89d57579-PXL_20251008_153502771.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\96e18aac-PXL_20251008_153427987.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\9bfcd6a1-PXL_20251008_152015583.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\9c2f26e2-PXL_20251008_151641854.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\9c949096-PXL_20251008_154435381.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\9ec3ff0c-PXL_20251008_154859395.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\a5da938a-PXL_20251008_154704401.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\a6d5b0b1-PXL_20251008_154649701.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\b2dc7ff6-PXL_20251008_155000714.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\b7916838-PXL_20251008_154536799.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\c4da191c-PXL_20251008_151953946.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\c53f2f17-PXL_20251008_155405521.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\c7c66ed2-PXL_20251008_154948614.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\d028b9ba-PXL_20251008_152048538.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\d11b9102-PXL_20251008_152234835.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\d315b8ec-PXL_20251008_155534999.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\d6873aa1-PXL_20251008_155527163.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\d71993d1-PXL_20251008_152023917.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\d9eeb2c7-PXL_20251008_152158227.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\e177299d-PXL_20251008_151259061.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\ed3d4dc3-PXL_20251008_151320858.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\f3270942-PXL_20251008_153405982.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\f4a4cdb6-PXL_20251008_151348800.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\f54f9061-PXL_20251008_154512641.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\f7cc8aa3-PXL_20251008_151907341.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\images\\fd7dc514-PXL_20251008_152322243.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\train\\labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 130.859.5 MB/s, size: 3178.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\validation\\labels... 16 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 16/16 42.9it/s 0.4s3s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\validation\\images\\061face6-PXL_20251008_151740773.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\validation\\images\\097dfb1e-PXL_20251008_151338760.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\validation\\images\\1b6b75db-PXL_20251008_155350118.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\validation\\images\\335b607e-PXL_20251008_153142804.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\validation\\images\\45197543-PXL_20251008_153251379.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\validation\\images\\764ec04f-PXL_20251008_151652730.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\validation\\images\\7e1f1b69-PXL_20251008_151757960.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\validation\\images\\a1fdf8bc-PXL_20251008_152216342.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\validation\\images\\a5a1c874-PXL_20251008_152038199.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\validation\\images\\c6d6e21a-PXL_20251008_154757828.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\validation\\images\\d907da71-PXL_20251008_154548875.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\validation\\images\\d95ae256-PXL_20251008_153435705.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\validation\\images\\dcd2bc98-PXL_20251008_155326918.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\validation\\images\\e945421f-PXL_20251008_154502942.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\validation\\images\\edf74d8a-PXL_20251008_151816402.MP.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\validation\\images\\f69cd8a6-PXL_20251008_152005865.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\data\\validation\\labels.cache\n",
      "Plotting labels to C:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\runs\\detect\\train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.005), 63 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\runs\\detect\\train\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50         0G      1.394       3.47      1.367         43        224: 100% ━━━━━━━━━━━━ 4/4 2.1s/it 8.4s2.9ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9s/it 1.9s\n",
      "                   all         16         16     0.0108          1      0.147      0.102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50         0G     0.9543      3.245      1.157         43        224: 100% ━━━━━━━━━━━━ 4/4 1.9it/s 2.2s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.2s/it 1.2s\n",
      "                   all         16         16    0.00909          1      0.561      0.406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50         0G     0.7176       2.86      1.028         43        224: 100% ━━━━━━━━━━━━ 4/4 2.1s/it 8.4s3.8ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.4s/it 3.4s\n",
      "                   all         16         16    0.00798          1      0.672      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50         0G     0.6759      2.165     0.9521         30        224: 100% ━━━━━━━━━━━━ 4/4 2.4s/it 9.6s1.9sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.2s/it 1.2s\n",
      "                   all         16         16    0.00728          1      0.713      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50         0G     0.6587      1.699     0.9393         38        224: 100% ━━━━━━━━━━━━ 4/4 1.9it/s 2.1s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.3s/it 1.3s\n",
      "                   all         16         16    0.00721          1      0.681      0.553\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50         0G     0.7134      1.547     0.9597         36        224: 100% ━━━━━━━━━━━━ 4/4 2.0it/s 2.0s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.3s/it 1.3s\n",
      "                   all         16         16     0.0067          1       0.64      0.531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50         0G     0.6696      1.333     0.9627         36        224: 100% ━━━━━━━━━━━━ 4/4 1.8it/s 2.3s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.3s/it 1.3s\n",
      "                   all         16         16    0.00637          1      0.717      0.578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50         0G     0.7064      1.296     0.9503         45        224: 100% ━━━━━━━━━━━━ 4/4 2.0it/s 2.0s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.2s/it 1.2s\n",
      "                   all         16         16      0.475          1      0.756      0.599\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50         0G     0.6688      1.213     0.9532         41        224: 100% ━━━━━━━━━━━━ 4/4 2.3it/s 1.7s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.1s/it 1.1s\n",
      "                   all         16         16      0.521      0.636      0.813      0.671\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50         0G     0.6558      1.131     0.9691         30        224: 100% ━━━━━━━━━━━━ 4/4 2.0it/s 2.0s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.1s/it 1.1s\n",
      "                   all         16         16       0.61      0.883      0.884      0.724\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50         0G     0.6523      1.023     0.9599         36        224: 100% ━━━━━━━━━━━━ 4/4 2.1it/s 1.9s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.2s/it 1.2s\n",
      "                   all         16         16      0.988       0.89      0.995      0.839\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50         0G     0.6506     0.9257     0.9474         41        224: 100% ━━━━━━━━━━━━ 4/4 2.3it/s 1.7s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.2s/it 1.2s\n",
      "                   all         16         16      0.966          1      0.995      0.828\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50         0G     0.6665     0.8911     0.9511         35        224: 100% ━━━━━━━━━━━━ 4/4 2.4it/s 1.7s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.1s/it 1.1s\n",
      "                   all         16         16      0.976      0.999      0.995      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50         0G      0.657     0.8464     0.9356         33        224: 100% ━━━━━━━━━━━━ 4/4 2.4it/s 1.7s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.2s/it 1.2s\n",
      "                   all         16         16      0.979      0.999      0.995      0.776\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50         0G     0.6498       0.86     0.9308         38        224: 100% ━━━━━━━━━━━━ 4/4 2.1it/s 1.9s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.1s/it 1.1s\n",
      "                   all         16         16          1      0.972      0.995      0.762\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50         0G     0.6286     0.7933     0.9435         37        224: 100% ━━━━━━━━━━━━ 4/4 2.5it/s 1.6s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.1s/it 1.1s\n",
      "                   all         16         16       0.81      0.884       0.89      0.714\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50         0G     0.6261     0.7782     0.9261         38        224: 100% ━━━━━━━━━━━━ 4/4 2.4it/s 1.7s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.1s/it 1.1s\n",
      "                   all         16         16       0.85      0.933      0.849      0.715\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50         0G     0.6287     0.7873     0.9436         34        224: 100% ━━━━━━━━━━━━ 4/4 2.2it/s 1.8s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.1s/it 1.1s\n",
      "                   all         16         16      0.815      0.966      0.978      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50         0G     0.5871     0.7547     0.9037         34        224: 100% ━━━━━━━━━━━━ 4/4 2.3it/s 1.7s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.1s/it 1.1s\n",
      "                   all         16         16      0.815       0.99      0.995      0.845\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50         0G     0.5901     0.7095     0.9105         38        224: 100% ━━━━━━━━━━━━ 4/4 2.3it/s 1.8s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.2s/it 1.2s\n",
      "                   all         16         16      0.952          1      0.995      0.866\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50         0G     0.6297     0.7156     0.9327         31        224: 100% ━━━━━━━━━━━━ 4/4 2.4it/s 1.7s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.2s/it 1.2s\n",
      "                   all         16         16      0.989          1      0.995      0.843\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50         0G     0.6138     0.7233     0.9464         42        224: 100% ━━━━━━━━━━━━ 4/4 2.5it/s 1.6s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.1s/it 1.1s\n",
      "                   all         16         16       0.99          1      0.995      0.833\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50         0G     0.6094     0.6904     0.9184         31        224: 100% ━━━━━━━━━━━━ 4/4 2.4it/s 1.7s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.1s/it 1.1s\n",
      "                   all         16         16      0.991          1      0.995      0.826\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50         0G     0.6038      0.679     0.9454         38        224: 100% ━━━━━━━━━━━━ 4/4 2.4it/s 1.7s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.1s/it 1.1s\n",
      "                   all         16         16      0.987          1      0.995      0.839\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50         0G     0.5833      0.708     0.9291         32        224: 100% ━━━━━━━━━━━━ 4/4 2.2it/s 1.8s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.3s/it 1.3s\n",
      "                   all         16         16      0.976          1      0.995      0.856\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50         0G     0.5803      0.658     0.9231         35        224: 100% ━━━━━━━━━━━━ 4/4 2.2it/s 1.9s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.1s/it 1.1s\n",
      "                   all         16         16      0.972          1      0.995      0.857\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50         0G     0.5747     0.6827     0.9213         30        224: 100% ━━━━━━━━━━━━ 4/4 2.0it/s 2.0s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6s/it 1.6s\n",
      "                   all         16         16      0.978          1      0.995      0.801\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50         0G     0.5898     0.6611     0.9357         37        224: 100% ━━━━━━━━━━━━ 4/4 1.9it/s 2.1s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.1s/it 1.1s\n",
      "                   all         16         16      0.984          1      0.995      0.806\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50         0G     0.6095     0.6634      0.932         42        224: 100% ━━━━━━━━━━━━ 4/4 2.0it/s 2.0s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.4s/it 1.4s\n",
      "                   all         16         16      0.993          1      0.995      0.836\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50         0G     0.5659     0.6199     0.9143         39        224: 100% ━━━━━━━━━━━━ 4/4 2.4it/s 1.6s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.2s/it 1.2s\n",
      "                   all         16         16       0.97          1      0.995      0.845\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 20, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "30 epochs completed in 0.034 hours.\n",
      "Optimizer stripped from C:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\runs\\detect\\train\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from C:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\runs\\detect\\train\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating C:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\runs\\detect\\train\\weights\\best.pt...\n",
      "Ultralytics 8.3.240  Python-3.10.19 torch-2.9.1+cpu CPU (12th Gen Intel Core i5-12450H)\n",
      "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.3s/it 1.3s\n",
      "                   all         16         16      0.952      0.999      0.995      0.866\n",
      "         Damaged_label         11         11          1      0.998      0.995      0.898\n",
      "            Good_label          5          5      0.905          1      0.995      0.834\n",
      "Speed: 0.1ms preprocess, 6.6ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\MSI\\Documents\\GitHub\\ClothTagNet\\runs\\detect\\train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.train(\n",
    "    data='data.yaml',\n",
    "    epochs=50,\n",
    "    imgsz=224,\n",
    "    patience=10,\n",
    "    device=0 if torch.cuda.is_available() else 'cpu',\n",
    "    workers=2,\n",
    "    weight_decay=0.005,\n",
    "    save=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4908a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=YOLO(r'runs\\detect\\train\\weights\\best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "10798d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>time</th>\n",
       "      <th>train/box_loss</th>\n",
       "      <th>train/cls_loss</th>\n",
       "      <th>train/dfl_loss</th>\n",
       "      <th>metrics/precision(B)</th>\n",
       "      <th>metrics/recall(B)</th>\n",
       "      <th>metrics/mAP50(B)</th>\n",
       "      <th>metrics/mAP50-95(B)</th>\n",
       "      <th>val/box_loss</th>\n",
       "      <th>val/cls_loss</th>\n",
       "      <th>val/dfl_loss</th>\n",
       "      <th>lr/pg0</th>\n",
       "      <th>lr/pg1</th>\n",
       "      <th>lr/pg2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.2913</td>\n",
       "      <td>1.39382</td>\n",
       "      <td>3.46988</td>\n",
       "      <td>1.36725</td>\n",
       "      <td>0.01084</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.14739</td>\n",
       "      <td>0.10179</td>\n",
       "      <td>0.54724</td>\n",
       "      <td>3.31793</td>\n",
       "      <td>0.96287</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13.9701</td>\n",
       "      <td>0.95433</td>\n",
       "      <td>3.24497</td>\n",
       "      <td>1.15683</td>\n",
       "      <td>0.00909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.56127</td>\n",
       "      <td>0.40650</td>\n",
       "      <td>0.82610</td>\n",
       "      <td>2.99463</td>\n",
       "      <td>0.93178</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0865</td>\n",
       "      <td>0.71763</td>\n",
       "      <td>2.85956</td>\n",
       "      <td>1.02757</td>\n",
       "      <td>0.00798</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.67244</td>\n",
       "      <td>0.45457</td>\n",
       "      <td>0.84129</td>\n",
       "      <td>2.68170</td>\n",
       "      <td>0.84365</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>37.5081</td>\n",
       "      <td>0.67593</td>\n",
       "      <td>2.16536</td>\n",
       "      <td>0.95206</td>\n",
       "      <td>0.00728</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.71334</td>\n",
       "      <td>0.52245</td>\n",
       "      <td>0.88497</td>\n",
       "      <td>2.37895</td>\n",
       "      <td>0.86233</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>41.1901</td>\n",
       "      <td>0.65866</td>\n",
       "      <td>1.69944</td>\n",
       "      <td>0.93933</td>\n",
       "      <td>0.00721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.68062</td>\n",
       "      <td>0.55252</td>\n",
       "      <td>0.75573</td>\n",
       "      <td>2.36570</td>\n",
       "      <td>0.85485</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch     time  train/box_loss  train/cls_loss  train/dfl_loss  \\\n",
       "0      1  10.2913         1.39382         3.46988         1.36725   \n",
       "1      2  13.9701         0.95433         3.24497         1.15683   \n",
       "2      3  26.0865         0.71763         2.85956         1.02757   \n",
       "3      4  37.5081         0.67593         2.16536         0.95206   \n",
       "4      5  41.1901         0.65866         1.69944         0.93933   \n",
       "\n",
       "   metrics/precision(B)  metrics/recall(B)  metrics/mAP50(B)  \\\n",
       "0               0.01084                1.0           0.14739   \n",
       "1               0.00909                1.0           0.56127   \n",
       "2               0.00798                1.0           0.67244   \n",
       "3               0.00728                1.0           0.71334   \n",
       "4               0.00721                1.0           0.68062   \n",
       "\n",
       "   metrics/mAP50-95(B)  val/box_loss  val/cls_loss  val/dfl_loss    lr/pg0  \\\n",
       "0              0.10179       0.54724       3.31793       0.96287  0.000050   \n",
       "1              0.40650       0.82610       2.99463       0.93178  0.000114   \n",
       "2              0.45457       0.84129       2.68170       0.84365  0.000176   \n",
       "3              0.52245       0.88497       2.37895       0.86233  0.000235   \n",
       "4              0.55252       0.75573       2.36570       0.85485  0.000292   \n",
       "\n",
       "     lr/pg1    lr/pg2  \n",
       "0  0.000050  0.000050  \n",
       "1  0.000114  0.000114  \n",
       "2  0.000176  0.000176  \n",
       "3  0.000235  0.000235  \n",
       "4  0.000292  0.000292  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r'runs\\detect\\train\\results.csv')\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
